# -*- coding: utf-8 -*-
"""gradients_test.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/17feC9ybeHEBWxtFLcAT4rE2r2WRE-Frn
"""

# Commented out IPython magic to ensure Python compatibility.
import tensorflow as tf
import matplotlib.pyplot as plt
# %matplotlib inline

def train():
    batch = 1000
    input_dimension = 10
    output_dimension = 3
    model_input = tf.random.uniform(shape=[batch,input_dimension],minval = 0,maxval = 3,dtype= tf.float32)
    labels = tf.one_hot(tf.random.uniform(shape=[batch],minval = 0,maxval = 3,dtype= tf.int32),depth=output_dimension)

    init = tf.keras.initializers.RandomNormal(stddev = 0.01)
    #init = tf.keras.initializers.glorot_normal()
    #init = tf.keras.initializers.glorot_uniform()
    #init = tf.keras.initializers.he_normal()
    #init = tf.keras.initializers.he_uniform()
    full_connection1 = tf.keras.layers.Dense(100,activation=None,kernel_initializer = init)
    full_connection2 = tf.keras.layers.Dense(100,activation=None,kernel_initializer = init)
    full_connection3 = tf.keras.layers.Dense(100,activation=None,kernel_initializer = init)
    full_connection4 = tf.keras.layers.Dense(100,activation=None,kernel_initializer = init)
    full_connection5 = tf.keras.layers.Dense(100,activation=None,kernel_initializer = init)
    full_connection6 = tf.keras.layers.Dense(100,activation=None,kernel_initializer = init)
    full_connection7 = tf.keras.layers.Dense(100,activation=None,kernel_initializer = init)
    output = tf.keras.layers.Dense(output_dimension,activation=None,kernel_initializer = init)

    def model(model_input):
        activ = tf.nn.relu
        with tf.GradientTape() as tape:
            fc1 = full_connection1(model_input)
            fc1_activation = tf.keras.layers.Activation(activ)(fc1)
            fc2 = full_connection1(fc1_activation)
            fc2_activation = tf.keras.layers.Activation(activ)(fc2)
            fc3 = full_connection1(fc2_activation)
            fc3_activation = tf.keras.layers.Activation(activ)(fc3)
            fc4 = full_connection1(fc3_activation)
            fc4_activation = tf.keras.layers.Activation(activ)(fc4)
            fc5 = full_connection1(fc4_activation)
            fc5_activation = tf.keras.layers.Activation(activ)(fc5)
            fc6 = full_connection1(fc5_activation)
            fc6_activation = tf.keras.layers.Activation(activ)(fc6)
            fc7 = full_connection1(fc6_activation)
            fc7_activation = tf.keras.layers.Activation(activ)(fc7)
            model = output(fc7_activation)

            loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=model,labels=labels))

        return tape.gradient(loss,fc1)
    obj = model(model_input)
    if obj == None:
        obj = tf.zeros(shape=[10000])
    else:
        obj = tf.reshape(obj,shape=[-1,])

    plt.plot(obj)
    plt.ylim(-0.001,0.001)
    plt.show()


if __name__ == "__main__":
    train()
